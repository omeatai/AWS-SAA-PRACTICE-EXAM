<details>
  <summary>Question 451</summary>

A company is migrating its applications and databases to the AWS Cloud.
The company will use Amazon Elastic Container Service (Amazon ECS), AWS Direct Connect, and Amazon RDS.
Which activities will be managed by the company's operational team?
(Choose three.)

-   [ ] A. Management of the Amazon RDS infrastructure layer, operating system, and platforms
-   [ ] B. Creation of an Amazon RDS DB instance and configuring the scheduled maintenance window
-   [ ] C. Configuration of additional software components on Amazon ECS for monitoring, patch management, log management, and host intrusion detection
-   [ ] D. Installation of patches for all minor and major database versions for Amazon RDS
-   [ ] E. Ensure the physical security of the Amazon RDS infrastructure in the data center
-   [ ] F. Encryption of the data that moves in transit through Direct Connect

</details>

<details>
  <summary>Answer</summary>

-   [ ] B. Creation of an Amazon RDS DB instance and configuring the scheduled maintenance window
-   [ ] C. Configuration of additional software components on Amazon ECS for monitoring, patch management, log management, and host intrusion detection
-   [ ] F. Encryption of the data that moves in transit through Direct Connect

Why these are the correct answers:

B. Creation of an Amazon RDS DB instance and configuring the scheduled maintenance window

-   [ ] The company is responsible for creating and configuring RDS instances, including setting maintenance windows.

C. Configuration of additional software components on Amazon ECS for monitoring, patch management, log management, and host intrusion detection

-   [ ] The company manages the software and tools within their ECS environment.

F. Encryption of the data that moves in transit through Direct Connect

-   [ ] The company is responsible for securing data in transit, including encryption over Direct Connect.

Why are the other answers wrong?

-   [ ] A and D. AWS manages the underlying infrastructure, OS, and patching for RDS.
-   [ ] E. AWS is responsible for the physical security of its data centers.

Therefore, Options B, C, and F are the activities managed by the company.

</details>
<details>
  <summary>Question 452</summary>

A company runs a Java-based job on an Amazon EC2 instance.
The job runs every hour and takes 10 seconds to run.
The job runs on a scheduled interval and consumes 1 GB of memory.
The CPU utilization of the instance is low except for short surges during which the job uses the maximum CPU available.
The company wants to optimize the costs to run the job.

Which solution will meet these requirements?

-   [ ] A. Use AWS App2Container (A2C) to containerize the job.
    Run the job as an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate with 0.5 virtual CPU (vCPU) and 1 GB of memory.
-   [ ] B. Copy the code into an AWS Lambda function that has 1 GB of memory.
    Create an Amazon EventBridge scheduled rule to run the code each hour.
-   [ ] C. Use AWS App2Container (A2C) to containerize the job.
    Install the container in the existing Amazon Machine Image (AMI).
    Ensure that the schedule stops the container when the task finishes.
-   [ ] D. Configure the existing schedule to stop the EC2 instance at the completion of the job and restart the EC2 instance when the next job starts.

</details>

<details>
  <summary>Answer</summary>

-   [ ] B. Copy the code into an AWS Lambda function that has 1 GB of memory.
    Create an Amazon EventBridge scheduled rule to run the code each hour.

Why these are the correct answers:

B. Copy the code into an AWS Lambda function that has 1 GB of memory.
Create an Amazon EventBridge scheduled rule to run the code each hour.

-   [ ] AWS Lambda is cost-effective for short-running, event-driven tasks.
-   [ ] EventBridge allows for scheduling Lambda functions, replacing the need for a continuously running EC2 instance.
-   [ ] Lambda's pay-per-use model aligns well with the job's short execution time and intermittent usage.

Why are the other answers wrong?

-   [ ] A. Running the job on Fargate is more expensive than Lambda for short, infrequent tasks.
-   [ ] C. Containerizing the job and running it on the existing EC2 instance does not optimize costs since the instance remains running.
-   [ ] D. Starting and stopping an EC2 instance adds overhead and is less efficient than using Lambda.

Therefore, Option B is the most cost-effective solution.

</details>
<details>
  <summary>Question 453</summary>

A company wants to implement a backup strategy for Amazon EC2 data and multiple Amazon S3 buckets.
Because of regulatory requirements, the company must retain backup files for a specific time period.
The company must not alter the files for the duration of the retention period.

Which solution will meet these requirements?

-   [ ] A. Use AWS Backup to create a backup vault that has a vault lock in governance mode.
    Create the required backup plan.
-   [ ] B. Use Amazon Data Lifecycle Manager to create the required automated snapshot policy.
-   [ ] C. Use Amazon S3 File Gateway to create the backup.
    Configure the appropriate S3 Lifecycle management.
-   [ ] D. Use AWS Backup to create a backup vault that has a vault lock in compliance mode.
    Create the required backup plan.

</details>

<details>
  <summary>Answer</summary>

-   [ ] D. Use AWS Backup to create a backup vault that has a vault lock in compliance mode.
    Create the required backup plan.

Why these are the correct answers:

D. Use AWS Backup to create a backup vault that has a vault lock in compliance mode.
Create the required backup plan.

-   [ ] AWS Backup centralizes backup management across AWS services.
-   [ ] Vault Lock in compliance mode prevents anyone, including the root user, from deleting or altering backups during the retention period, meeting the regulatory requirement.

Why are the other answers wrong?

-   [ ] A. Governance mode allows privileged users to delete backups, which does not meet the requirement of immutability.
-   [ ] B. Data Lifecycle Manager automates snapshot management for EBS volumes but does not cover S3 backups or provide immutable storage.
-   [ ] C. S3 File Gateway is for integrating on-premises applications with S3 and does not provide backup and retention management like AWS Backup.

Therefore, Option D is the only solution that ensures immutable backups with AWS Backup and Vault Lock in compliance mode.

</details>
<details>
  <summary>Question 454</summary>

A company has resources across multiple AWS Regions and accounts.
A newly hired solutions architect discovers a previous employee did not provide details about the resources inventory.
The solutions architect needs to build and map the relationship details of the various workloads across all accounts.
Which solution will meet these requirements in the MOST operationally efficient way?

-   [ ] A. Use AWS Systems Manager Inventory to generate a map view from the detailed view report.
-   [ ] B. Use AWS Step Functions to collect workload details.
    Build architecture diagrams of the workloads manually.
-   [ ] C. Use Workload Discovery on AWS to generate architecture diagrams of the workloads.
-   [ ] D. Use AWS X-Ray to view the workload details.
    Build architecture diagrams with relationships.

</details>

<details>
  <summary>Answer</summary>

-   [ ] C. Use Workload Discovery on AWS to generate architecture diagrams of the workloads.

Why these are the correct answers:

C. Use Workload Discovery on AWS to generate architecture diagrams of the workloads.

-   [ ] Workload Discovery on AWS automatically discovers and maps dependencies between applications and infrastructure, providing a visual representation of workloads.
-   [ ] It reduces the manual effort involved in documenting and understanding complex environments.

Why are the other answers wrong?

-   [ ] A. Systems Manager Inventory collects software and configuration data from EC2 instances but does not provide automated mapping of workload relationships.
-   [ ] B. Using Step Functions to collect details and manually building diagrams is time-consuming and inefficient.
-   [ ] D. AWS X-Ray is for tracing and analyzing distributed applications, not for discovering and mapping infrastructure.

Therefore, Option C is the most operationally efficient solution.

</details>
<details>
  <summary>Question 455</summary>

A company uses AWS Organizations.
The company wants to operate some of its AWS accounts with different budgets.
The company wants to receive alerts and automatically prevent provisioning of additional resources on AWS accounts when the allocated budget threshold is met during a specific period.
Which combination of solutions will meet these requirements? (Choose three.)

-   [ ] A. Use AWS Budgets to create a budget.
    Set the budget amount under the Cost and Usage Reports section of the required AWS accounts.
-   [ ] B. Use AWS Budgets to create a budget.
    Set the budget amount under the Billing dashboards of the required AWS accounts.
-   [ ] C. Create an IAM user for AWS Budgets to run budget actions with the required permissions.
-   [ ] D. Create an IAM role for AWS Budgets to run budget actions with the required permissions.
-   [ ] E. Add an alert to notify the company when each account meets its budget threshold.
    Add a budget action that selects the IAM identity created with the appropriate config rule to prevent provisioning of additional resources.
-   [ ] F. Add an alert to notify the company when each account meets its budget threshold.
    Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources.

</details>

<details>
  <summary>Answer</summary>

-   [ ] B. Use AWS Budgets to create a budget.
    Set the budget amount under the Billing dashboards of the required AWS accounts.
-   [ ] D. Create an IAM role for AWS Budgets to run budget actions with the required permissions.
-   [ ] F. Add an alert to notify the company when each account meets its budget threshold.
    Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources.

Why these are the correct answers:

B. Use AWS Budgets to create a budget.
Set the budget amount under the Billing dashboards of the required AWS accounts.

-   [ ] AWS Budgets allows you to set custom budgets to track costs.

D. Create an IAM role for AWS Budgets to run budget actions with the required permissions.

-   [ ] An IAM role provides secure permissions for AWS Budgets to take actions.

F. Add an alert to notify the company when each account meets its budget threshold.
Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources.

-   [ ] Budget actions can be configured to prevent resource provisioning, and SCPs can enforce these restrictions across accounts.

Why are the other answers wrong?

-   [ ] A. Budget amounts are not set under Cost and Usage Reports.
-   [ ] C. Using an IAM user for budget actions is less secure than using an IAM role.
-   [ ] E. Config rules do not prevent resource provisioning in the same way that SCPs do.

Therefore, Options B, D, and F are the correct solutions.

</details>
<details>
  <summary>Question 456</summary>

A company runs applications on Amazon EC2 instances in one AWS Region.
The company wants to back up the EC2 instances to a second Region.
The company also wants to provision EC2 resources in the second Region and manage the EC2 instances centrally from one AWS account.
Which solution will meet these requirements MOST cost-effectively?

-   [ ] A. Create a disaster recovery (DR) plan that has a similar number of EC2 instances in the second Region.
    Configure data replication.
-   [ ] B. Create point-in-time Amazon Elastic Block Store (Amazon EBS) snapshots of the EC2 instances.
    Copy the snapshots to the second Region periodically.
-   [ ] C. Create a backup plan by using AWS Backup.
    Configure cross-Region backup to the second Region for the EC2 instances.
-   [ ] D. Deploy a similar number of EC2 instances in the second Region.
    Use AWS DataSync to transfer the data from the source Region to the second Region.

</details>

<details>
  <summary>Answer</summary>

-   [ ] C. Create a backup plan by using AWS Backup.
    Configure cross-Region backup to the second Region for the EC2 instances.

Why these are the correct answers:

C. Create a backup plan by using AWS Backup.
Configure cross-Region backup to the second Region for the EC2 instances.

-   [ ] AWS Backup centralizes backup management and supports cross-Region backups.
-   [ ] It provides a cost-effective way to manage backups across Regions.

Why are the other answers wrong?

-   [ ] A. Maintaining a similar number of EC2 instances in the DR Region increases costs.
-   [ ] B. Manually copying EBS snapshots is complex and does not provide centralized management.
-   [ ] D. Using DataSync is for data migration, not for backup and recovery.
    It also involves managing EC2 instances in both Regions.

Therefore, Option C is the most cost-effective and efficient solution.

</details>
<details>
  <summary>Question 457</summary>

A company that uses AWS is building an application to transfer data to a product manufacturer.
The company has its own identity provider (IdP).
The company wants the IdP to authenticate application users while the users use the application to transfer data.
The company must use Applicability Statement 2 (AS2) protocol.

Which solution will meet these requirements?

-   [ ] A. Use AWS DataSync to transfer the data.
    Create an AWS Lambda function for IdP authentication.
-   [ ] B. Use Amazon AppFlow flows to transfer the data.
    Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication.
-   [ ] C. Use AWS Transfer Family to transfer the data.
    Create an AWS Lambda function for IdP authentication.
-   [ ] D. Use AWS Storage Gateway to transfer the data.
    Create an Amazon Cognito identity pool for IdP authentication.

</details>

<details>
  <summary>Answer</summary>

-   [ ] C. Use AWS Transfer Family to transfer the data.
    Create an AWS Lambda function for IdP authentication.

Why these are the correct answers:

C. Use AWS Transfer Family to transfer the data.
Create an AWS Lambda function for IdP authentication.

-   [ ] AWS Transfer Family supports the AS2 protocol for secure data transfer.
-   [ ] Lambda functions can be used for custom authentication logic with the company's IdP.

Why are the other answers wrong?

-   [ ] A. AWS DataSync is for large-scale data migration, not for AS2 transfers.
-   [ ] B. Amazon AppFlow is for data transfer between SaaS applications, not for AS2.
-   [ ] D. AWS Storage Gateway is for hybrid cloud storage, not for AS2.
    Amazon Cognito is for user authentication, not IdP integration in this context.

Therefore, Option C is the correct solution.

</details>
<details>
  <summary>Question 458</summary>

A solutions architect is designing a REST API in Amazon API Gateway for a cash payback service.
The application requires 1 GB of memory and 2 GB of storage for its computation resources.
The application will require that the data is in a relational format.
Which additional combination of AWS services will meet these requirements with the LEAST administrative effort? (Choose two.)

-   [ ] A. Amazon EC2
-   [ ] B. AWS Lambda
-   [ ] C. Amazon RDS
-   [ ] D. Amazon DynamoDB
-   [ ] E. Amazon Elastic Kubernetes Services (Amazon EKS)

</details>

<details>
  <summary>Answer</summary>

-   [ ] B. AWS Lambda
-   [ ] C. Amazon RDS

Why these are the correct answers:

B. AWS Lambda

-   [ ] Lambda provides a serverless compute environment that can meet the application's memory and storage requirements with minimal administration.

C. Amazon RDS

-   [ ] Amazon RDS is a managed relational database service that meets the requirement for relational data storage and reduces administrative overhead.

Why are the other answers wrong?

-   [ ] A and E. Amazon EC2 and Amazon EKS require more administrative effort for managing infrastructure.
-   [ ] D. Amazon DynamoDB is a NoSQL database and does not meet the relational data requirement.

Therefore, Options B and C are the most suitable choices.

</details>
<details>
  <summary>Question 459</summary>

A company uses AWS Organizations to run workloads within multiple AWS accounts.
A tagging policy adds department tags to AWS resources when the company creates tags.
An accounting team needs to determine spending on Amazon EC2 consumption.
The accounting team must determine which departments are responsible for the costs regardless of AWS account.
The accounting team has access to AWS Cost Explorer for all AWS accounts within the organization and needs to access all reports from Cost Explorer.
Which solution meets these requirements in the MOST operationally efficient way?

-   [ ] A. From the Organizations management account billing console, activate a user-defined cost allocation tag named department.
    Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.
-   [ ] B. From the Organizations management account billing console, activate an AWS-defined cost allocation tag named department.
    Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.
-   [ ] C. From the Organizations member account billing console, activate a user-defined cost allocation tag named department.
    Create one cost report in Cost Explorer grouping by the tag name, and filter by EC2.
-   [ ] D. From the Organizations member account billing console, activate an AWS-defined cost allocation tag named department.
    Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.

</details>

<details>
  <summary>Answer</summary>

-   [ ] A. From the Organizations management account billing console, activate a user-defined cost allocation tag named department.
    Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.

Why these are the correct answers:

A. From the Organizations management account billing console, activate a user-defined cost allocation tag named department.
Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.

-   [ ] Activating the tag in the management account ensures that the cost allocation tag is applied across all accounts in the organization.
-   [ ] Cost Explorer can then be used to generate a report grouped by the department tag, providing a consolidated view of EC2 spending.

Why are the other answers wrong?

-   [ ] B. AWS-defined cost allocation tags cannot be created or activated by users.
-   [ ] C and D. Activating the tag in a member account does not provide a consolidated view across the organization.

Therefore, Option A is the most operationally efficient solution.

</details>
<details>
  <summary>Question 460</summary>

A company wants to securely exchange data between its software as a service (SaaS) application Salesforce account and Amazon S3.
The company must encrypt the data at rest by using AWS Key Management Service (AWS KMS) customer managed keys (CMKs).
The company must also encrypt the data in transit.
The company has enabled API access for the Salesforce account.

-   [ ] A. Create AWS Lambda functions to transfer the data securely from Salesforce to Amazon S3.
-   [ ] B. Create an AWS Step Functions workflow.
    Define the task to transfer the data securely from Salesforce to Amazon S3.
-   [ ] C. Create Amazon AppFlow flows to transfer the data securely from Salesforce to Amazon S3.
-   [ ] D. Create a custom connector for Salesforce to transfer the data securely from Salesforce to Amazon S3.

</details>

<details>
  <summary>Answer</summary>

-   [ ] C. Create Amazon AppFlow flows to transfer the data securely from Salesforce to Amazon S3.

Why these are the correct answers:

C. Create Amazon AppFlow flows to transfer the data securely from Salesforce to Amazon S3.

-   [ ] Amazon AppFlow is designed for secure data transfer between SaaS applications and AWS services like S3.
-   [ ] AppFlow supports encryption at rest with KMS and encryption in transit.

Why are the other answers wrong?

-   [ ] A. Lambda functions can transfer data but require more custom code and management for security and encryption.
-   [ ] B. Step Functions orchestrate workflows but do not directly transfer data.
    They would need to integrate with other services, adding complexity.
-   [ ] D. Creating a custom connector is more complex and time-consuming than using AppFlow.

Therefore, Option C provides the most straightforward and secure solution.

</details>
